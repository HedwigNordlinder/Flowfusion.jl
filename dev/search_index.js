var documenterSearchIndex = {"docs":
[{"location":"#Flowfusion","page":"Home","title":"Flowfusion","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for Flowfusion.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Flowfusion.DistInterpolatingDiscreteFlow","page":"Home","title":"Flowfusion.DistInterpolatingDiscreteFlow","text":"DistInterpolatingDiscreteFlow(D::UnivariateDistribution)\n\nD controls the schedule. Note: both training and inference expect the model to output logits, unlike the other InterpolatingDiscreteFlow (where the user needs a manual softmax for inference).\n\n\n\n\n\n","category":"type"},{"location":"#Flowfusion.DistNoisyInterpolatingDiscreteFlow","page":"Home","title":"Flowfusion.DistNoisyInterpolatingDiscreteFlow","text":"DistNoisyInterpolatingDiscreteFlow(; D1=Beta(2,2), D2=Beta(2,2), ωu=0.2, dummy_token=nothing)\n\nConvex 3-way path over {X0, Uniform, X1} with distribution-backed schedules:   κ₁(t) = cdf(D1,t)   κ̃₂(t) = cdf(D2,t)   κ₂(t) = ωu * (1 - κ₁(t)) * κ̃₂(t)        # uniform amplitude scaled by ωu ∈ [0,1)   κ₃(t) = 1 - κ₁(t) - κ₂(t)\n\nDerivatives:   dκ₂(t) = ωu * ( -(dκ₁) * κ̃₂ + (1 - κ₁) * dκ̃₂ ),   dκ₃ = -(dκ₁ + dκ₂)\n\nωu directly controls the uniform noise amount; set ωu=0 for no-uniform, ωu→1 for max-gated uniform. Note: both training and inference expect the model to output logits, unlike the other NoisyInterpolatingDiscreteFlow (where the user needs a manual softmax for inference).\n\n\n\n\n\n","category":"type"},{"location":"#Flowfusion.Guide","page":"Home","title":"Flowfusion.Guide","text":"Guide(H::AbstractArray)\n\nWrapping a model prediction in Guide instructs the solver that the prediction points to X1 from the current state, instead of being a prediction of X1 itself. Used for ManifoldStates where the prediction is a tangent \n\n\n\n\n\n","category":"type"},{"location":"#Flowfusion.MaskedState","page":"Home","title":"Flowfusion.MaskedState","text":"MaskedState(S::State, cmask, lmask)\n\nWraps a State with a conditioning mask (cmask) and a loss mask (lmask).\n\nConditioning mask behavior:\n\nThe typical use is that it makes sense, during training, to construct the conditioning mask on the training observation, X1. During inference, the conditioning mask (and conditioned-upon state) has to be present onX1`. This dictates the behavior of the masking:\n\nWhen bridge() is called, the mask, and the state where cmask=1, are inherited from X1.\nWhen gen() is called, the state and mask will be propogated from X0 through all of the Xts.\n\nLoss mask behavior:\n\nWhere lmask=0, that observation (where the shape/size of the observation is determined by the difference in dimensions between the mask and the state) is not included in the loss.\n\n\n\n\n\n","category":"type"},{"location":"#Flowfusion.NoisyInterpolatingDiscreteFlow-Union{Tuple{Any}, Tuple{T}} where T","page":"Home","title":"Flowfusion.NoisyInterpolatingDiscreteFlow","text":"NoisyInterpolatingDiscreteFlow(κ₁, κ₂, dκ₁, dκ₂, dummy_token)\nNoisyInterpolatingDiscreteFlow(noise; K = 1, dummy_token = nothing) - Uses default cosine schedule, where `noise` is the maximum amplitude of the uniform noise component.\nNoisyInterpolatingDiscreteFlow() - Uses default cosine schedule and noise = 0.2.\n\nA convex mixture of X0, uniform noise, and X1. Equation 10 in https://arxiv.org/pdf/2407.15595 Compared to InterpolatingDiscreteFlow, it encourages the model to make multiple switches during inference. κ₁, κ₂ are the schedules for target token interpolation and uniform noise probability. dκ₁, dκ₂ are the derivatives of κ₁, κ₂. Defaults to using a cosine schedule. K=2 will resolve the discrete states later than K=1. If K>1 things might break if your X0 is not the dummy_token (also called the masked token) which should be passed to NoisyInterpolatingDiscreteFlow.\n\n\n\n\n\n","category":"method"},{"location":"#Flowfusion.apply_tangent_coordinates-Tuple{ForwardBackward.ManifoldState, Any}","page":"Home","title":"Flowfusion.apply_tangent_coordinates","text":"apply_tangent_coordinates(Xt::ManifoldState, ξ; retraction_method=default_retraction_method(Xt.M))\n\nreturns X̂₁ where each point is the result of retracting Xt by the corresponding tangent coordinate vector ξ.\n\n\n\n\n\n","category":"method"},{"location":"#Flowfusion.batch-Union{Tuple{Vector{T}}, Tuple{T}} where T<:ForwardBackward.ContinuousState","page":"Home","title":"Flowfusion.batch","text":"batch(Xs::Vector{T}; dims_from_end = 1)\n\nDoesn't handle padding. Add option to pad if batching along dims that don't have the same length.\n\n\n\n\n\n","category":"method"},{"location":"#Flowfusion.cmask!-Tuple{Any, Any, Any}","page":"Home","title":"Flowfusion.cmask!","text":"cmask!(Xt_state, X1_state, cmask)\ncmask!(Xt, X1)\n\nApplies, in place, a conditioning mask, where only elements (or slices) of Xt where cmask is 1 are noised. When cmask is 0, the elements are forced to be equal to X1.\n\n\n\n\n\n","category":"method"},{"location":"#Flowfusion.dense-Tuple{ForwardBackward.DiscreteState}","page":"Home","title":"Flowfusion.dense","text":"dense(X::DiscreteState; T = Float32)\n\nConverts X to an appropriate dense representation. If X is a DiscreteState, then X is converted to a CategoricalLikelihood with default eltype Float32. If X is a \"onehot\" CategoricalLikelihood then X is converted to a fully dense one.\n\n\n\n\n\n","category":"method"},{"location":"#Flowfusion.endslices-Tuple{Any, Any}","page":"Home","title":"Flowfusion.endslices","text":"endslices(a,m)\n\nReturns a view of a where slices specified by m are selected. m can be multidimensional, but the dimensions of m must match the last dimensions of a. For example, if m is a boolean array, then size(a)[ndims(a)-ndims(m):end] == size(m).\n\n\n\n\n\n","category":"method"},{"location":"#Flowfusion.gen-Tuple{Tuple{Vararg{Union{ForwardBackward.Process, FProcess}}}, Tuple{Vararg{Union{ForwardBackward.State, Guide, MaskedState}}}, Any, AbstractVector}","page":"Home","title":"Flowfusion.gen","text":"gen(P, X0, model, steps; tracker=Returns(nothing), midpoint = false)\n\nConstructs a sequence of (stochastic) bridges between X0 and the predicted X̂₁ under the process P. P, X0, can also be tuples where the Nth element of P will be used for the Nth elements of X0 and model. model is a function that takes t (scalar) and Xₜ (optionally a tuple) and returns hat (a UState, a flat tensor with the right shape, or a tuple of either if you're combining processes). If X0 is a MaskedState, then anything in X̂₁ will be conditioned on X0 where the conditioning mask X0.cmask is 1.\n\n\n\n\n\n","category":"method"},{"location":"#Flowfusion.mask-Tuple{Tuple, Tuple}","page":"Home","title":"Flowfusion.mask","text":"mask(X, Y)\n\nIf Y is a MaskedState, mask(X, Y) returns a MaskedState with the content of X where elements of Y.cmask are 1, and Y where Y.cmask is 0. cmask and lmask are inherited from Y. If Y is not a MaskedState, mask(X, Y) returns X.\n\n\n\n\n\n","category":"method"},{"location":"#Flowfusion.onehot-Tuple{ForwardBackward.DiscreteState{<:AbstractArray{<:Integer}}}","page":"Home","title":"Flowfusion.onehot","text":"onehot(X)\n\nRerturns a state where X.state is a onehot array.\n\n\n\n\n\n","category":"method"},{"location":"#Flowfusion.tangent_guide-Tuple{Union{MaskedState, ForwardBackward.ManifoldState}, Union{MaskedState, ForwardBackward.ManifoldState}}","page":"Home","title":"Flowfusion.tangent_guide","text":"tangent_guide(Xt::ManifoldState, X1::ManifoldState)\n\nComputes the coordinate vector (in the default basis) pointing from Xt to X1.\n\n\n\n\n\n","category":"method"},{"location":"#Flowfusion.unhot-Tuple{ForwardBackward.DiscreteState{<:Union{OneHotArrays.OneHotArray, OneHotArrays.OneHotMatrix}}}","page":"Home","title":"Flowfusion.unhot","text":"unhot(X)\n\nReturns a state where X.state is not onehot.\n\n\n\n\n\n","category":"method"},{"location":"#Flowfusion.unmask-Tuple{MaskedState}","page":"Home","title":"Flowfusion.unmask","text":"unmask(X)\n\nunmask(X) = X, unless X is a MaskedState, in which case X.S is returned.\n\n\n\n\n\n","category":"method"},{"location":"#Flowfusion.unwrap-Tuple{ForwardBackward.State}","page":"Home","title":"Flowfusion.unwrap","text":"unwrap(X)\n\nReturns the underlying state or dist of X (X.state if X is a State, X.dist if X is a StateLikelihood, and X.S.state if X is a MaskedState, etc). Unlike tensor(X) this does not flatten the state.\n\n\n\n\n\n","category":"method"}]
}
